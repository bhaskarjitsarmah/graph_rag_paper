{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")\n",
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\")\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"eval_dataset_Creation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings # To create embeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore # To connect with the Vectorstore\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining globle variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"earning_calls_ground_truth.csv\")\n",
    "\n",
    "# df['ticker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_ticker_dict = {\n",
    " \"Adani Enterprises Ltd\": \"adanient\",\n",
    " \"Adani Ports and Special Economic Zone Ltd\": \"adaniports\",\n",
    " \"Apollo Hospitals\": \"apollohosp\",\n",
    " \"Asian Paints\": \"asianpaint\",\n",
    " \"Axis Bank\": \"axisbank\",\n",
    " \"Bajaj Auto\": \"bajaj-auto\",\n",
    " \"Bajaj Finance\": \"bajfinance\",\n",
    " \"Bharat Petroleum\": \"bpcl\",\n",
    " \"Bharti Airtel\": \"bhartiartl\",\n",
    " \"Britannia Industries\": \"britannia\",\n",
    " \"Cipla\": \"cipla\",\n",
    " \"Divi's Laboratories\": \"divislab\",\n",
    " \"Dr. Reddy's Laboratories\": \"drreddy\",\n",
    " \"Eicher Motors\": \"eichermot\",\n",
    " \"Grasim Industries\": \"grasim\",\n",
    " \"HCLTech\": \"hcltech\",\n",
    " \"HDFC Bank\": \"hdfcbank\",\n",
    " \"HDFC Life\": \"hdfclife\",\n",
    " \"Hero MotoCorp\": \"heromotoco\",\n",
    " \"Hindalco Industries\": \"hindalco\",\n",
    " \"Hindustan Unilever\": \"hindunilvrv\",\n",
    " \"ICICI Bank\": \"icicibank\",\n",
    " \"IndusInd Bank\": \"indusindbk\",\n",
    " \"Infosys\": \"infy\",\n",
    " \"JSW Steel\": \"jswsteel\",\n",
    " \"Kotak Mahindra Bank\": \"kotakbank\",\n",
    " \"Larsen & Toubro\": \"lt\",\n",
    " \"LTIMindtree\": \"ltim\",\n",
    " \"Mahindra & Mahindra\": \"m&m\",\n",
    " \"Maruti Suzuki\": \"maruti\",\n",
    " \"Reliance Industries\": \"reliance\",\n",
    " \"SBI Life Insurance Company\": \"sbilife\",\n",
    " \"State Bank of India\": \"sbin\",\n",
    " \"Sun Pharma\": \"sunpharma\",\n",
    " \"Tata Consultancy Services\": \"tcs\",\n",
    " \"Tata Consumer Products\": \"tataconsum\",\n",
    " \"Tata Steel\": \"tatasteel\",\n",
    " \"Tech Mahindra\": \"techm\",\n",
    " \"Titan Company\": \"titan\",\n",
    " \"UltraTech Cement\": \"ultracemco\",\n",
    " \"UPL\": \"upl\",\n",
    " \"Wipro\": \"wipro\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in company_ticker_dict.items():\n",
    "#     temp = df[df['ticker']==value]\n",
    "#     print(f\"company name: {key}\")\n",
    "#     print(f\"data shape: {temp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = 'earning-calls-euclidean'\n",
    "TOP_K = 4\n",
    "QUARTER = \"Q1\"\n",
    "YEAR = \"FY24\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "index = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings) # loading the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"),\n",
    "        (\"human\", \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {query}\\nAnswer: \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def get_rag_chain(retriver=None):\n",
    "    rag_chain_from_docs = (\n",
    "        RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "        | chat_template\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    rag_chain_with_source = RunnableParallel(\n",
    "        {\"context\": retriver, \"query\": RunnablePassthrough()}\n",
    "    ).assign(answer=rag_chain_from_docs)\n",
    "    return rag_chain_with_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5) Adani Enterprises Ltd.pdf\n",
      "(10, 5) Adani Ports and Special Economic Zone Ltd.pdf\n",
      "(10, 5) Apollo Hospitals.pdf\n",
      "(10, 5) Asian Paints.pdf\n",
      "(10, 5) Axis Bank.pdf\n",
      "(10, 5) Bajaj Auto.pdf\n",
      "(10, 5) Bajaj Finance.pdf\n",
      "(8, 5) Bharat Petroleum.pdf\n",
      "(10, 5) Bharti Airtel.pdf\n",
      "(10, 5) Britannia Industries.pdf\n",
      "(10, 5) Cipla.pdf\n",
      "(10, 5) Divi's Laboratories.pdf\n",
      "(10, 5) Dr. Reddy's Laboratories.pdf\n",
      "(10, 5) Eicher Motors.pdf\n",
      "(10, 5) Grasim Industries.pdf\n",
      "(10, 5) HCLTech.pdf\n",
      "(10, 5) HDFC Bank.pdf\n",
      "(10, 5) HDFC Life.pdf\n",
      "(10, 5) Hero MotoCorp.pdf\n",
      "(10, 5) Hindalco Industries.pdf\n",
      "(0, 5) Hindustan Unilever.pdf\n",
      "(10, 5) ICICI Bank.pdf\n",
      "(10, 5) IndusInd Bank.pdf\n",
      "(10, 5) Infosys.pdf\n",
      "(11, 5) JSW Steel.pdf\n",
      "(10, 5) Kotak Mahindra Bank.pdf\n",
      "(10, 5) Larsen & Toubro.pdf\n",
      "(10, 5) LTIMindtree.pdf\n",
      "(10, 5) Mahindra & Mahindra.pdf\n",
      "(10, 5) Maruti Suzuki.pdf\n",
      "(10, 5) Reliance Industries.pdf\n",
      "(10, 5) SBI Life Insurance Company.pdf\n",
      "(10, 5) State Bank of India.pdf\n",
      "(10, 5) Sun Pharma.pdf\n",
      "(10, 5) Tata Consultancy Services.pdf\n",
      "(10, 5) Tata Consumer Products.pdf\n",
      "(10, 5) Tata Steel.pdf\n",
      "(10, 5) Tech Mahindra.pdf\n",
      "(10, 5) Titan Company.pdf\n",
      "(10, 5) UltraTech Cement.pdf\n",
      "(10, 5) UPL.pdf\n",
      "(10, 5) Wipro.pdf\n"
     ]
    }
   ],
   "source": [
    "for key, value in company_ticker_dict.items():\n",
    "    questions = []\n",
    "    contexts = []\n",
    "    answers = []\n",
    "    ground_truths = []\n",
    "\n",
    "    FILENAME = f\"{key}.pdf\"\n",
    "    retriver = index.as_retriever(search_kwargs={\"filter\": {\"quarter\": QUARTER, \"filename\": FILENAME, \"year\": YEAR}, \"k\": TOP_K})\n",
    "    rag_chain_with_source = get_rag_chain(retriver=retriver)\n",
    "\n",
    "    temp = df[df['ticker']==value]\n",
    "    for idx, row in temp.iterrows():\n",
    "        response = rag_chain_with_source.invoke(row[\"questions_asked\"])\n",
    "        # answers\n",
    "        questions.append(row['questions_asked'])\n",
    "        contexts.append([context.page_content for context in response['context']])\n",
    "        answers.append(response['answer'])\n",
    "        ground_truths.append(row['answers'])\n",
    "        \n",
    "    res_df = pd.DataFrame({\"question\": questions, \"answer\": answers, \"contexts\": contexts, \"ground_truth\": ground_truths, \"file_name\": [FILENAME for _ in range(len(questions))]})\n",
    "    print(res_df.shape, FILENAME)\n",
    "    # res_df.to_csv(key+\".csv\", index=False)\n",
    "    res_df.to_csv(\"eval_data/\" + key + \".csv\", index=False)    \n",
    "    res_df.to_json(\"eval_data_json/\"+ key + \".json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
